"""DataCite DOI record discovery."""

from typing import Dict, Iterator, Tuple

import requests

from sindex.core.dates import _norm_date_iso
from sindex.core.http import make_session
from sindex.core.ids import _norm_doi

from .client import get_datacite_record_by_norm_doi
from .constants import BASE_API_URL


def get_datacite_doi_record(
    doi: str, session: requests.Session | None = None
) -> dict | None:
    """
    Retrieve a single DataCite metadata record for a given DOI or DOI URL.

    Args:
        doi: DOI string (e.g., "10.5061/dryad.ab12cd3") or full DOI URL.
        session: Optional shared `requests.Session` (uses retry/backoff if None).

    Returns:
        The JSON-decoded DataCite record (`data` object) if found, or `None` if
        the DOI does not exist or returns an error.

    Raises:
        requests.HTTPError: If an unexpected HTTP error occurs (e.g., 5xx not handled by retries).

    Notes:
        - The DOI is normalized with _norm_doi to lowercase and stripped of any "https://doi.org/" prefix.
        - DataCite api direct link: https://api.datacite.org/dois/{doi}
    """
    print(f"[DATACITE] get_datacite_doi_record - Fetching record for DOI: {doi}")
    norm_doi = _norm_doi(doi)
    if not norm_doi:
        print(f"[DATACITE] get_datacite_doi_record - ERROR: Invalid DOI: {doi}")
        raise ValueError(f"Invalid DOI: {doi}")

    print(f"[DATACITE] get_datacite_doi_record - Normalized DOI: {norm_doi}")
    s = session or make_session(allowed_methods=("GET",))
    result = get_datacite_record_by_norm_doi(norm_doi, session=s)
    if result:
        print(
            f"[DATACITE] get_datacite_doi_record - Successfully retrieved record for: {norm_doi}"
        )
    else:
        print(f"[DATACITE] get_datacite_doi_record - No record found for: {norm_doi}")
    return result


def stream_datacite_records(
    start_date: str,
    end_date: str,
    page_size: int = 1000,
    session: requests.Session | None = None,  # pass a shared session
    timeout: Tuple[int, int] = (10, 240),  # (connect, read) seconds
) -> Iterator[Dict]:
    """
    Stream raw DataCite Dataset records created within a date range.

    This function performs a cursor-based harvest of DataCite's /dois API using:
        - a fixed resource type filter (`Dataset`)
        - a created-date range query `[start_date TO end_date]` (both included)
        - pagination via `links.next` (DataCite's cursor API)

    Instead of collecting all API results into memory, this function yields
    each record immediately as a Python dictionary, making it suitable for
    large-scale harvesting and low-memory pipelines.

    Args:
        start_date: Inclusive ISO date string (YYYY-MM-DD).
        end_date: Inclusive ISO date string (YYYY-MM-DD).
        page_size: Number of records per API page (cursor). Max is 1000 for DataCite.
        user_agent: Optional override for the User-Agent header.
        session: Shared requests session (recommended) otherwise a new one created.
        timeout: (connect, read) timeout tuple.
            connect = How long to wait while trying to open a TCP connection to the server.
            read_timeout: How long to wait after the connection is established for the server to start sending data.

    Yields:
        dict:
            Each raw DataCite record (`payload["data"][i]`), exactly as
            returned by the REST API. No transformation is applied.
    """
    s = session or make_session()
    base_url = BASE_API_URL
    params = {
        "query": f"types.resourceTypeGeneral:Dataset AND created:[{start_date} TO {end_date}]",
        "page[size]": page_size,
        "page[cursor]": 1,
    }

    while True:
        r = s.get(base_url, params=params, timeout=timeout)
        r.raise_for_status()
        payload = r.json()

        for rec in payload.get("data", []):
            yield rec

        next_url = payload.get("links", {}).get("next")
        if not next_url:
            break

        base_url = next_url
        params = {}


def fetch_datacite_pubdate(doi: str, session: requests.Session | None = None) -> str:
    """
    Fetch a publication/created date for a DOI from the DataCite API and normalize it.

    Args:
        doi_or_doi_url: DOI identifier or DOI URL.
        session: Optional shared `requests.Session` (uses retry/backoff if None).

    Returns:
        ISO-8601 string (normalized) if available, else "".
    """
    datacite_record = get_datacite_doi_record(doi)
    if not datacite_record:  # None (404 / invalid DOI)
        return ""

    attrs = datacite_record.get("attributes") or {}

    # Try "created", "published", or "issued" dates in this order of preference
    for key in ("created", "published", "issued"):
        val = attrs.get(key)
        if not val:
            continue
        try:
            return _norm_date_iso(val)
        except Exception:
            continue

    return ""
